import asyncio
from datetime import datetime, timedelta, timezone

import feedparser
from apscheduler.schedulers.asyncio import AsyncIOScheduler

from db.postgres import (
    init_pg_pool,
    get_all_group_ids,
    get_shops_for_group,
)
from db.redis_client import get_seen_ids, add_seen_id
from api.client import fetch_latest_from_rss, scrape_listing_page
from notifier.telegram_client import send_message

# Th·ªùi gian t·ªëi thi·ªÉu ƒë·ªÉ t√≠nh ‚Äú24h qua‚Äù (UTC)
def utc_cutoff(hours: int = 24) -> datetime:
    return datetime.now(timezone.utc) - timedelta(hours=hours)

async def count_and_mark_new(shop_name: str, cutoff: datetime) -> int:
    # """
    # - ƒê·ªçc RSS feed c·ªßa shop.
    # - V·ªõi m·ªói entry, t√°ch listing_id.
    # - N·∫øu listing_id ch∆∞a seen, scrape JSON‚ÄëLD ƒë·ªÉ l·∫•y datePublished.
    # - N·∫øu datePublished >= cutoff, ƒë·∫øm v√†o v√† mark seen.
    # """
    seen: set[str] = await get_seen_ids(shop_name)
    new_count = 0

    # D√πng RSS ƒë·ªÉ l·∫•y entry URLs (c√≥ th·ªÉ v√†i ch·ª•c items)
    feed = feedparser.parse(f"https://www.etsy.com/shop/{shop_name}/rss")

    for entry in feed.entries:
        # T√°ch listing_id
        link = entry.link
        if "/listing/" in link:
            listing_id = link.rstrip("/").split("/")[-2]
        else:
            continue  # skip n·∫øu kh√¥ng ƒë√∫ng format

        # B·ªè qua n·∫øu ƒë√£ seen
        if listing_id in seen:
            continue

        # L·∫•y detail ƒë·ªÉ x√°c ƒë·ªãnh ng√†y t·∫°o ch√≠nh x√°c
        details = await scrape_listing_page(link)
        date_str = details.get("create_date")
        try:
            # JSON‚ÄëLD datePublished lu√¥n ·ªü format ISO
            dt = datetime.fromisoformat(date_str)
        except Exception:
            # fallback n·∫øu kh√¥ng parse ƒë∆∞·ª£c
            continue

        # Ch·ªâ ƒë·∫øm n·∫øu th·ª±c s·ª± t·∫°o trong 24h qua
        if dt >= cutoff:
            new_count += 1
            # ƒë√°nh d·∫•u seen ƒë·ªÉ kh√¥ng b√°o l·∫°i v·ªÅ sau
            await add_seen_id(shop_name, listing_id)

    return new_count

async def send_daily_summary():
    # """
    # Job b√°o c√°o h√†ng ng√†y cho m·ªói group l√∫c 07:00 Asia/Bangkok.
    # """
    pg_pool = await init_pg_pool()
    cutoff = utc_cutoff(24)
    today = datetime.now().strftime("%Y-%m-%d")

    # L·∫•y t·∫•t c·∫£ group ƒë√£ ƒëƒÉng k√Ω
    group_ids = await get_all_group_ids(pg_pool)

    for group_id in group_ids:
        # Danh s√°ch shop nh√≥m n√†y theo d√µi
        shops = await get_shops_for_group(pg_pool, group_id)
        lines = []

        for shop in shops:
            cnt = await count_and_mark_new(shop, cutoff)
            lines.append(f"‚Ä¢ {shop}: {cnt} s·∫£n ph·∫©m m·ªõi trong 24h qua")

        if not lines:
            text = (
                f"üìä B√°o c√°o h√†ng ng√†y ({today}):\n"
                "Nh√≥m ch∆∞a theo d√µi shop n√†o."
            )
        else:
            text = (
                f"üìä *B√°o c√°o h√†ng ng√†y* ({today}):\n\n" +
                "\n".join(lines)
            )

        await send_message(group_id, text)

def main():
    # Scheduler ch·∫°y job h√†ng ng√†y l√∫c 07:00 Asia/Bangkok
    scheduler = AsyncIOScheduler(timezone="Asia/Bangkok")
    scheduler.add_job(send_daily_summary, "cron", hour=7, minute=0)
    scheduler.start()

    # Gi·ªØ loop ch·∫°y li√™n t·ª•c
    asyncio.get_event_loop().run_forever()

if __name__ == "__main__":
    main()
